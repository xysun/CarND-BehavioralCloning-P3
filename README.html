<!DOCTYPE html>
<html>
<head>
<title>README</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
<base href='file:\\\C:\Users\AW51R2\code\carnd\P3\'/>
</head>
<body>
<h2>Project 3 documentation</h2>
<p>This markdown file documents the details for my Project 3 submission.</p>
<h3>Training data</h3>
<p>Training data is obtained through driving manually several laps with a PS4 joystick:</p>
<ul>
<li>One lap of driving that keeps to center of the road</li>
<li>Simulate &quot;recovery driving&quot;, by driving offcenter (without recording), and then record steering back to the center. This is done for all corners, for both drifting to left/right side.</li>
<li>For small road segments that the model (will be discussed later) demonstrates difficulty, some more manual driving is done.</li>
</ul>
<p>In total, 34k images (center, left, right camera) were recorded.</p>
<h3>Image augmentation</h3>
<p>To generate more training data without actually driving, below augmentation methods were used:</p>
<ul>
<li>Flip each image and record opposite steering angles.</li>
<li>Brightness adjust (<a href="https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.q08muecvh">reference</a>)</li>
<li>Use both left and right camera image, while adjust steering by a fixed delta (0.25)</li>
</ul>
<p>After augmentation and using both left and right camera images, a total of 52k images were used.</p>
<p>Below are example images: </p>
<p>Original image:</p>
<p><img src="img1.png" alt="Original image" /></p>
<p>Flipped:</p>
<p><img src="img1_flipped.png" alt="Flipped image" /></p>
<p>Brightness adjusted:</p>
<p><img src="img1_brightness_adjusted.png" alt="Brightness adjusted" /></p>
<p>Left camera:</p>
<p><img src="img1_left.png" alt="Left" /></p>
<p>Right camera:</p>
<p><img src="img1_right.png" alt="Right" /></p>
<h3>Data normalization</h3>
<p>Every image was resized to 64x64, all the RGB values were normalized to range of [-0.5, 0.5]. </p>
<h3>Training, validation split</h3>
<p>To avoid overfitting, all data were split into training/validation using scikit-learn's <code>train_test_split</code> method. <code>test_size</code> was set to 25% of all data.</p>
<h3>Model description</h3>
<p>I used same model from <a href="https://github.com/commaai/research/blob/master/train_steering_model.py">comma.ai</a> here.</p>
<p>This is a model with 3 convolution layers followed by 1 fully connected layer. There's a dropout layer after both the last convolution layer and the fully connected layer. Exponential Linear Units (ELU) was used as activation layer. Adam optimizer was used with mean squared error (mse) as objective.</p>
<p>Below are the dimensions:</p>
<ul>
<li>Conv1: filters = 16, kernel size = 8x8, strides = 4x4</li>
<li>Conv2: filters = 32, kernel size = 5x5, strides = 2x2</li>
<li>Conv2: filters = 64, kernel size = 5x5, strides = 2x2</li>
<li>Dropout rate after 3 convolution layers: 0.2</li>
<li>Fully connected layer: 512</li>
<li>Dropout rate after the fully connected layer: 0.5</li>
</ul>
<h3>Training</h3>
<p>The model was trained using batch size 32 and in 10 epochs. </p>
<h3>Performance</h3>
<p>The model performed well on track 1, kept within the drive-able potion of road. </p>
<p>I also tried running the model on track 2, it behaved well there too. The only thing I noticed is since track 2 has slopes, in rare occasions the car may not have enough initial speed to climb a steep uphill. The model kept the car in the right direction though.</p>
<h3>Further work</h3>
<p>The model did not use any other driving data (throttle, whether it's breaking, speed). It would be interesting to explore how we can incorporate these additional features into self driving. </p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
